import json
from glob import glob

import streamlit as st

from midi_tokenizers.midi_tokenizers.midi_tokenizer import MidiTokenizer
from midi_tokenizers.midi_trainable_tokenizers.bpe_tokenizer import BpeMidiTokenizer
from midi_tokenizers.midi_trainable_tokenizers.awesome_midi_tokenzier import AwesomeMidiTokenizer
from midi_tokenizers.midi_tokenizers_generation.base_tokenizer_generator import TokenizerFactory, name_to_base_factory_map


class BpeMidiTokenizerFactory(TokenizerFactory):
    tokenizer_desc = """
    This tokenizer can be trained on tokens generated by on of the no-loss models,
    which is passed to it by base_tokenizer parameter.


    You can train new tokenizers by messing with scripts/train_bpe.py
    """

    @staticmethod
    def select_parameters() -> dict:
        trained_tokenizers_options = glob("dumps/tokenizers/*.json")
        path = st.selectbox(label="pre-trained tokenizers", options=trained_tokenizers_options)
        with open(path) as file:
            serialized_tokenizer = json.load(file)
        serialized_tokenizer["bpe_tokenizer"] = json.loads(serialized_tokenizer["bpe_tokenizer"])
        st.json(serialized_tokenizer, expanded=False)
        return {"path": path}

    @staticmethod
    def create_tokenizer(parameters: dict) -> BpeMidiTokenizer:
        return BpeMidiTokenizer.from_file(**parameters)


class AwesomeMidiTokenizerFactory(TokenizerFactory):
    tokenizer_desc = """
    This tokenizer can be trained on tokens generated by on of the no-loss models,
    which is passed to it by base_tokenizer parameter.
    """

    @staticmethod
    def select_parameters() -> dict:
        trained_tokenizers_options = glob("dumps/awesome_tokenizers/*.json")
        path = st.selectbox(label="pre-trained tokenizers", options=trained_tokenizers_options)
        with open(path) as file:
            serialized_tokenizer = json.load(file)
        serialized_tokenizer["bpe_tokenizer"] = json.loads(serialized_tokenizer["bpe_tokenizer"])
        st.json(serialized_tokenizer, expanded=False)
        return {"path": path}

    @staticmethod
    def create_tokenizer(parameters: dict) -> BpeMidiTokenizer:
        return AwesomeMidiTokenizer.from_file(**parameters)


name_to_factory_map = name_to_base_factory_map | {
    "BpeMidiTokenizer": BpeMidiTokenizerFactory(),
    "AwesomeMidiTokenizer": AwesomeMidiTokenizerFactory(),
}


def tokenizer_info(name: str):
    """
    Get the description of the tokenizer.

    Parameters:
        name (str): Name of the tokenizer.

    Returns:
        str: Description of the tokenizer.
    """
    return name_to_factory_map[name].tokenizer_desc


def generate_tokenizer_with_streamlit(name: str) -> MidiTokenizer:
    """
    Generate a tokenizer with parameters selected using Streamlit widgets.

    Parameters:
        name (str): Name of the tokenizer.

    Returns:
        MidiTokenizer: Instance of the created tokenizer.
    """
    factory = name_to_factory_map[name]
    parameters = factory.select_parameters()

    return factory.create_tokenizer(parameters)


def generate_tokenizer(name: str, parameters: dict) -> MidiTokenizer:
    """
    Generate a tokenizer with the given parameters.

    Parameters:
        name (str): Name of the tokenizer.
        parameters (dict): Dictionary of parameters for the tokenizer.

    Returns:
        MidiTokenizer: Instance of the created tokenizer.
    """
    factory = name_to_factory_map[name]
    return factory.create_tokenizer(parameters)
